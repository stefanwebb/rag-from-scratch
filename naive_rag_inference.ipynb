{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load \"Vector DB\" and run RAG query on pre-trained instruct LLM\n",
    "Simply appends retrieved chunks to query. No fancy pipeline steps or dedicated Vector DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from threading import Thread\n",
    "import time\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TextIteratorStreamer,\n",
    "    TextStreamer,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load chunk contents and embedding index\n",
    "* TIL that WSL2 only has 50% of the system RAM by default. I had to increase it via `.wslconfig` so we can load both the search index and the raw chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Database for chunks\n",
    "index = faiss.read_index(\"wikipedia-en.index\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in Chunks\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
     ]
    }
   ],
   "source": [
    "chunks = []    \n",
    "embeddings_path = '/home/stefanwebb/embeddings/wikimedia/wikipedia/20231101.en'\n",
    "files = [f\"train-{idx:05d}-of-00041.parquet\" for idx in range(41)]\n",
    "\n",
    "print(\"Reading in Chunks\")\n",
    "for idx in range(len(files)):\n",
    "    print(f\"x\", end=\"\")\n",
    "    chunks_file = os.path.join(embeddings_path, f'chunks-{idx:05d}-of-00041.pkl')\n",
    "    with open(chunks_file, 'rb') as f:\n",
    "        chunks.extend(pickle.load(f))\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49522046, 49522046)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ntotal, len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.8e-08, 0.430605624)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: Following code doesn't seem to get size of all objects references by these\n",
    "# sys.getsizeof(index) / 10**9, sys.getsizeof(chunks) / 10**9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LLM to run queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.8: Fast Mistral patching. Transformers = 4.43.4.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4090. Max memory: 23.988 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.0.dev20240829+cu124. CUDA = 8.9. CUDA Toolkit = 12.4.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28+d444815.d20240829. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:209: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:210: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:211: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:209: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:210: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:211: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    }
   ],
   "source": [
    "# query_model = \"google/gemma-2b-it\"\n",
    "query_model = \"/home/stefanwebb/models/llms/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "max_seq_length = 2048\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"/home/stefanwebb/models/llms/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct RAG Query and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32768, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32768, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query_streamed(query, query_model):\n",
    "    system_prompt = \"You are a helpful assistant who answers question truthfully to the best of your knowledge. You decline to answer if you do not know the answer.\"\n",
    "\n",
    "    chat = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "        },\n",
    "        \n",
    "        {\n",
    "\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{query}\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    formatted_prompt = tokenizer.apply_chat_template(\n",
    "        chat, tokenize=False, add_generation_prompt=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    streamer = TextStreamer(\n",
    "        tokenizer, skip_prompt=True, skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    _ = model.generate(**inputs, streamer=streamer, max_new_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_encoder = SentenceTransformer(\"/home/stefanwebb/models/llms/multi-qa-MiniLM-L6-cos-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_chunks(query: str, k=1) -> str:\n",
    "    \"\"\"\n",
    "    Find closest chunk for a given query.\n",
    "    \"\"\"\n",
    "    embeddings = query_encoder.encode([query])\n",
    "    D, I = index.search(embeddings, k)\n",
    "    return D, I\n",
    "\n",
    "\n",
    "def run_rag_query_streamed(query, query_model, k=3):\n",
    "    # Retrieve most similar chunks\n",
    "    D, I = top_k_chunks(query, k=k)\n",
    "    # formatted_chunks = '\\n\\n'.join([\"Document: \" + chunks[i] for i in I[0]])\n",
    "    formatted_chunks = ' '.join([chunks[i] for i in I[0]])\n",
    "    \n",
    "    # rag_query = f\"Answer the query below and ground your answer in facts contained in the documents below:\\n\\nQuery: {query}\\n\\n{formatted_chunks}\"\n",
    "\n",
    "    rag_query = f\"{formatted_chunks}\\n\\nAnswer the following question: {query}\"\n",
    "\n",
    "    # DEBUG\n",
    "    # print(rag_query)\n",
    "    # print(\"\\n\")\n",
    "\n",
    "    run_query_streamed(rag_query, query_model)\n",
    "\n",
    "    # for i, d in zip(I[0], D[0]):\n",
    "    #     print(d, chunks[i])\n",
    "    #     print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug Examples\n",
    "Compare answers to questions, with and without context from most similar document chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral-7B-Instruct-v0.3\n",
      "Abraham Lincoln grew a beard primarily for practical reasons. In the mid-19th century, beards were common among men, but Lincoln did not have a beard during his first term as a U.S. Representative. After losing the Senate race in 1858, he grew a beard as a way to differentiate himself from his opponents in his presidential campaign in 1860. The beard also helped to hide a condition he had called \"tuberculosis laryngitis,\" which caused his voice to be weak and hoarse. Additionally, the beard may have helped to make him appear more mature and serious, which could have been beneficial in a time of national crisis.\n",
      "\n",
      "Mistral-7B-Instruct-v0.3 + RAG\n",
      "Abraham Lincoln grew a beard in response to a letter he received from a young girl named Grace Bedell during the 1860 presidential campaign. She suggested that he grow a beard to improve his appearance and make him look more presidential. Lincoln responded to the letter, but made no promises. However, within a month, he grew a full beard.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Why did Abraham Lincoln grow a beard?\"\n",
    "\n",
    "print(\"Mistral-7B-Instruct-v0.3\")\n",
    "run_query_streamed(query, model)\n",
    "print()\n",
    "\n",
    "print(\"Mistral-7B-Instruct-v0.3 + RAG\")\n",
    "run_rag_query_streamed(query, model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral-7B-Instruct-v0.3\n",
      "Glacier caves, also known as moulins or ice caves, are formed in glaciers due to the melting of ice. Here's a simplified explanation of the process:\n",
      "\n",
      "1. Meltwater: As snow accumulates on a glacier, it eventually turns into ice. Over time, this ice melts due to various factors like geothermal heat, precipitation, and air temperature. This meltwater collects in crevasses and other low spots within the glacier.\n",
      "\n",
      "2. Enlargement of crevasses: The meltwater continues to flow, enlarging the crevasses. As the crevasse deepens, it may eventually connect with the surface of the glacier, forming a vertical shaft known as a moulin.\n",
      "\n",
      "3. Drainage: The meltwater drains into the underlying rock or bedrock, carving out a tunnel or cave-like structure. This process continues as long as the conditions (temperature, precipitation, etc.) allow for melting and drainage.\n",
      "\n",
      "4. Collapse: Over time, the roof of the cave may become too thin to support itself, causing it to collapse. This can create a large, open cavity within the glacier.\n",
      "\n",
      "5. Exposure: If the glacier retreats or melts away, the cave may be exposed to the surface, allowing people to explore it. However, these caves are dangerous and should only be entered by experienced climbers and cavers.\n",
      "\n",
      "Mistral-7B-Instruct-v0.3 + RAG\n",
      "Glacier caves are formed when meltwater from a glacier erodes passages within the glacier, creating a network of tunnels and chambers. Over time, the ice in these passages can become thicker and more stable, forming stalagmites, stalactites, and ice columns. These caves are prone to collapse due to exposure to warm temperatures or running water. They are often found in glaciated areas, where the surrounding landscape has been shaped by repeated glacial advances and retreats. The specific geology of the area can also influence the formation of glacier caves, as certain types of rock, such as limestone, are more prone to forming caves than others.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"How are glacier caves formed?\"\n",
    "\n",
    "print(\"Mistral-7B-Instruct-v0.3\")\n",
    "run_query_streamed(query, model)\n",
    "print()\n",
    "\n",
    "print(\"Mistral-7B-Instruct-v0.3 + RAG\")\n",
    "run_rag_query_streamed(query, model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral-7B-Instruct-v0.3\n",
      "A beer can pyramid, also known as a can pyramid or a can sculpture, is a structure made by stacking beer cans in a specific pattern to create a pyramid shape. This is often done as a fun and creative activity, and the stability of the structure depends on the number of cans used and the arrangement of the cans in the pyramid. The cans are usually empty, but some people use full cans to create a more stable structure. It's important to note that this activity should be done responsibly and safely, and the cans should be disposed of properly after the pyramid is complete.\n",
      "\n",
      "Mistral-7B-Instruct-v0.3 + RAG\n",
      "A beer can pyramid, often referred to as a beeramid, is a pyramid structure made from empty beer cans. It is built as more empty cans become available over the course of a night, a week, or a month. These structures are usually temporary, and are either cleaned up or knocked over eventually.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is a beer can pyramid?\"\n",
    "\n",
    "print(\"Mistral-7B-Instruct-v0.3\")\n",
    "run_query_streamed(query, model)\n",
    "print()\n",
    "\n",
    "print(\"Mistral-7B-Instruct-v0.3 + RAG\")\n",
    "run_rag_query_streamed(query, model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] a beer can pyramid, often called a beeramid as a portmanteau, is a pyramid made from discarded beer cans. beer can pyramids are built as empty beer cans became available, slowly growing as the night ( or week or month ) wears on. in most cases, though, they are temporary structures, eventually being cleaned up or accidentally knocked over. [SEP] [CLS] beeramid may refer to : beer can pyramid, a pyramid made of empty cans of beer beeramid ( comic ), a comic in the daily cardinal, a student newspaper for uw - madison [SEP] [CLS] from their introduction in the 1930s up until the 1960s, most beer cans were made of steel and had a flat top into which one needed to punch one or two holes with a can piercer, euphemistically called a \" churchkey \". with the advent of the \" pop - top \" aluminum can, this type of beverage can has disappeared almost entirely. the reception for churchkey's retro style can has not been entirely positive, with some beer enthusiasts dubbing it \" the most hipster beer in the world \". [SEP] [CLS] a common drink on the menu of most tiki bars, over 50 variations of a mug meant to specifically hold a fog cutter cocktail are known to exist, many in radically different designs than the one used by trader vic's. [SEP] [CLS] the term \" bar \" is derived from the specialized counter on which drinks are served. the \" back bar \" is a set of shelves of glasses and bottles behind that counter. in some establishments, the back bar is elaborately decorated with woodwork, etched glass, mirrors, and lights. [SEP] [CLS] table beer table beer ( tafelbier, biere de table ) is a low - alcohol ( typically not over 1. 5 % ) brew sold in large bottles to be enjoyed with meals. the last decade it has gradually lost popularity due to the growing consumption of soft drinks and bottled water. it comes in blonde or brown versions. table beer used to be served in school refectories until the 1980s ; in the early 21st century, several organizations made proposals to reinstate this custom as the table beer is considered more healthy than soft drinks. some bars serve a glass of draft lager with a small amount of table beer added, to take away the fizziness and act as a sweetener, in limburg it is referred to as a \" half om \". [SEP] [CLS] when the can is opened, the pressure in the can quickly drops, causing the pressurised gas and beer inside the widget to jet out from the hole. this agitation on the surrounding beer causes a chain reaction of bubble formation throughout the beer. the result, when the can's content is then poured, is a surging mixture in the glass of very small gas bubbles and liquid. [SEP] [CLS] the fatal glass of beer can refer to the following : [SEP] [CLS] a bonus round is played after the end of each level, in which six cans of beer ( or root beer ) are placed on the bar. a masked figure shakes five of the cans, then pounds the bar to shuffle them. choosing the one unshaken can awards bonus points, while choosing any other results in the bartender being sprayed in the face ; in the latter case, the unshaken can flashes briefly to indicate its position. [SEP] [CLS] a hallmark of tiki bars are specialty drinks, some of which may be unique to a bar and the recipes for which were often carefully guarded in order to prevent imitation from competing bars or from customers trying to recreate a drink at home. [SEP]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is a beer can pyramid?\"\n",
    "D, I = top_k_chunks(query, k=10)\n",
    "formatted_chunks = ' '.join([chunks[i] for i in I[0]])\n",
    "print(formatted_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral-7B-Instruct-v0.3\n",
      "As of my last update, the world record for the largest beer can pyramid was set by the University of Wisconsin-La Crosse Eagle's Nest Co-ed Fraternity and Sorority Life on March 23, 2019. They stacked 10,000 cans to create a pyramid that was 11.5 meters tall and 7.6 meters wide. This record was verified by Guinness World Records. However, records can change over time, so it's always a good idea to check the latest records from a reliable source.\n",
      "\n",
      "Mistral-7B-Instruct-v0.3 + RAG\n",
      "I don't have real-time data or the ability to check the current world record for a beer can pyramid. However, as of the information provided, the beer can pyramid built by the Melbourne University Student Union in 2005 contained 10,660 cans and was over 5 meters high. It was submitted for a place in the Guinness Book of Records, but I don't have the information to confirm if it actually set a record. For the most accurate and up-to-date information, I would recommend checking the Guinness World Records official website.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the current world record for a beer can pyramid?\"\n",
    "\n",
    "print(\"Mistral-7B-Instruct-v0.3\")\n",
    "run_query_streamed(query, model)\n",
    "print()\n",
    "\n",
    "print(\"Mistral-7B-Instruct-v0.3 + RAG\")\n",
    "run_rag_query_streamed(query, model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] as of july 2010, layar had 1, 000 layers. as of september 2011, layar had 2, 993 layers. [SEP] [CLS] size ( 300, 300 ) ; [SEP] [CLS] top 10 in order of height [SEP] [CLS] trivia the \" world's longest churro \" was produced during the 2000 festival. it was 77 m long and weighed 30 kg. [SEP] [CLS] in mathematics 204 is a refactorable number. 204 is a square pyramidal number : 204 balls may be stacked in a pyramid whose base is an 8 Ã— 8 square. its square, 2042 = 41616, is the fourth square triangular number. as a figurate number, 204 is also a nonagonal number and a truncated triangular pyramid number. 204 is a member of the mian - chowla sequence. [SEP] [CLS] description annual, c. 100 â€“ 1000 cm tall. [SEP] [CLS] here, the valid instances are those graphs whose maximum independent set size is either at most 5 or at least 10. [SEP] [CLS] maximum dimensions are shown in metres, after 10 â€“ 20 years. [SEP] [CLS] see also ramesseum magician's box list of largest monoliths in the world [SEP] [CLS] length : 4635 width : 2000 height : 1100 width : 2680 [SEP]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the current world record for a can pyramid?\"\n",
    "D, I = top_k_chunks(query, k=10)\n",
    "formatted_chunks = ' '.join([chunks[i] for i in I[0]])\n",
    "print(formatted_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] it was featured in season 13 the simpsons episode \" weekend at burnsie's \" where homer simpson ( after he smokes medicinal marijuana ) gets ready for work and pictures his world as a psychedelic wonderland. [SEP] [CLS] couch gag this episode's couch gag features an ident commissioned by the uk network channel 4, in 2006 ( though first aired in july 2007 ), for use before its broadcasts of simpsons episodes. the writers added in all - new sections in order to theme the gag around the super bowl which was broadcast near the airing of this episode. in the original ident, homer places his six - pack of duff beer on a hammock in the simpson's backyard. when he sits down, he inadvertently fires the six - pack into the sky, only for them to get caught on the power lines hanging over the garden. when homer manages to get up to the beer cans, climbing up the family's garden tree, he is shocked by the electricity now running through the six - pack. he is continuously shocked as the camera pans up to a birds - eye view of springfield. every time homer is shocked, an area loses power, which slowly start to make out the shape of the channel 4 logo. in the updated couch gag version, homer sits down to watch the super bowl, only to discover he has misplaced his six - pack of duff. he discovers bart has tossed it onto the overhead power line in the family backyard, and when homer retrieves it, he is shocked. he continues to get shocked as the camera pans to a birds - eye view of springfield until the town's power goes out ( the channel 4 logo is noticeable, but the power outages have been changed so it isn't as obvious ). [SEP] [CLS] when bart reaches for the cupcakes and collapses, it is a parody of a scene in a clockwork orange, where the main character alex reaches for a woman's breasts. duff is shown to be a sponsor in the 1960 united states presidential debates. the duff clock is a parody of the \" it's a small world \" clock. in the duff tv advertisement, a group of women were leading an anti - sexism protest in front of the mcmahon and tate building, a reference to the advertising agency from bewitched. the scene toward the end where moe points toward individual customers declaring they will \" be back \" before pointing toward and addressing the viewer ( later revealed to be barney via a cutaway ) is a parody of the end of the film reefer madness. the final scene, where homer and marge cycle into the distance while \" raindrops keep fallin'on my head \" plays is a reference to the film butch cassidy and the sundance kid. homer's song \" it was a very good beer \" is sung to the tune of the 1961 song \" it was a very good year \" ; one of its lyrics is homer stating he stayed up and listened to the music of the british band queen. bart sitting in the chair, stroking the hamster is a reference to james bond character ernst stavro blofeld, who strokes a cat in his chair. lisa imagines bart as a hamster trapped in a maze saying \" help me! help me! \" which is a reference to the fly. lisa claims she was laughing at a joke from the series herman's head, a series that features lisa's voice actor yeardley smith and fellow cast member hank azaria. bart makes several actions reminiscent of the three stooges through out the episode. [SEP]\n"
     ]
    }
   ],
   "source": [
    "query = \"Which Simpsons episode featured a beer can pyramid outside of Duff Gardens?\"\n",
    "D, I = top_k_chunks(query, k=3)\n",
    "formatted_chunks = ' '.join([chunks[i] for i in I[0]])\n",
    "print(formatted_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] z billy zaharopoulos [SEP] [CLS] robert myron zarem ( september 30, 1936 â€“ september 26, 2021 ), known as bobby zarem, was an american publicist. after starting his own publicity agency in 1974, zarem created lengthy, personalized pitch letters, a business style, and many campaigns. his former clients included dustin hoffman, cher, arnold schwarzenegger, michael jackson, diana ross, michael douglas, michael caine, sophia loren, ann - margret, and alan alda, among others. [SEP] [CLS] z mike zaher morgan zeba [SEP] [CLS] z joe zawinul lev zhurbin torrie zito bob zurke [SEP] [CLS] mohed altrad ( ) is a french - syrian billionaire businessman, rugby chairman and writer, born c. march 1948. he was born to a very young mother and his bedouin father gave him away to his grandparents at age four following his mother's death. in 2015, altrad was named ernst & young world entrepreneur of the year. [SEP] [CLS] luciano belviso ( born august 18, 1983 ) is an italian entrepreneur, manager and aerospace engineer. he is founder and ceo of blackshape aircraft. [SEP] [CLS] robert abi nader ( ) is a lebanese fashion designer. [SEP] [CLS] mike zagurski clay zavada seby zavala brad ziegler alan zinter [SEP] [CLS] z benjamin zephaniah ( born 1958 ) [SEP] [CLS] z carl zuckmayer arnold zweig stefan zweig [SEP]\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is Benjamin Geza Affleck?\"\n",
    "D, I = top_k_chunks(query, k=10)\n",
    "formatted_chunks = ' '.join([chunks[i] for i in I[0]])\n",
    "print(formatted_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral-7B-Instruct-v0.3\n",
      "Benjamin Geza Affleck is a well-known American actor, filmmaker, and screenwriter. He was born on August 15, 1972. Affleck gained fame for his roles in films such as \"Good Will Hunting,\" for which he won an Academy Award for Best Original Screenplay along with Matt Damon, and \"Argo,\" for which he won the Academy Award for Best Picture as a producer. He is also known for his roles in films like \"Dazed and Confused,\" \"Chasing Amy,\" \"Gone Baby Gone,\" and \"The Town.\" In addition to acting, Affleck has directed films such as \"Gone Baby Gone,\" \"The Town,\" and \"Argo.\" He is also a political activist and has been involved in various philanthropic efforts.\n",
      "\n",
      "Mistral-7B-Instruct-v0.3 + RAG\n",
      "Benjamin Geza Affleck is an American actor, film director, screenwriter, and producer. He is known for his work in films such as \"Good Will Hunting,\" \"Argo,\" and \"Gone Baby Gone.\" He has won multiple awards, including two Academy Awards, for his acting and directing work. He is also known for his romantic relationship with actress Jennifer Lopez and his brother, actor Casey Affleck.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is Benjamin Geza Affleck?\"\n",
    "\n",
    "print(\"Mistral-7B-Instruct-v0.3\")\n",
    "run_query_streamed(query, model)\n",
    "print()\n",
    "\n",
    "print(\"Mistral-7B-Instruct-v0.3 + RAG\")\n",
    "run_rag_query_streamed(query, model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating whether failure to retrieve relevant chunks is due to search index or document/query encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] another attempt to break the world record beer can pyramid was made with beer cans over 5 metres high and contained 10, 660 cans. it was built by the melbourne university student union in 2005, and was featured on blokesworld and in mx. [SEP] [CLS] it has five hand pumps serving real ale and a beer garden, and was submitted for a place in the guinness book of records. [SEP] [CLS] to date the brewery has created over 300 different beers. [SEP]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the current world record for a beer can pyramid?\"\n",
    "D, I = top_k_chunks(query, k=3)\n",
    "formatted_chunks = ' '.join([chunks[i] for i in I[0]])\n",
    "print(formatted_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44419780, 15182634, 32287273])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] on 23 september 2000, the malaysian can team, consisting of 12 college students from the inti college subang jaya, malaysia built a free standing can pyramid created from 9, 455 empty aluminium drink cans in 24 minutes at the mid valley megamall in kuala lumpur, malaysia. it had a square base of cans, measuring. this feat made a successful entry into the guinness world record and to - date this record has yet to be broken. [SEP]'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[44419780 - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing similarity of query to retrieved chunks and the non-retrieved chunk that contains the necessary fact\n",
    "emb_query = query_encoder.encode([query])\n",
    "emb_chunk0 = query_encoder.encode([chunks[44419780]])\n",
    "emb_chunk1 = query_encoder.encode([chunks[44419780 - 1]])\n",
    "emb_chunk2 = query_encoder.encode([chunks[15182634]])\n",
    "emb_chunk3 = query_encoder.encode([chunks[32287273]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80006427\n",
      "0.6656804\n",
      "0.5796839\n",
      "0.61451036\n"
     ]
    }
   ],
   "source": [
    "for emb in [emb_chunk0, emb_chunk1, emb_chunk2, emb_chunk3]:\n",
    "    score1 = np.dot(emb_query.flatten(), emb.flatten())\n",
    "    print(score1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44419780, 15182634, 32287273, 44019041, 10667840, 17866603,\n",
       "       44684914, 16419147, 48056004, 47488175, 20744553, 23933341,\n",
       "       34792865, 32287276,  5588295, 38474929,  6724587, 26383078,\n",
       "       47576167,  6152881, 17653053, 39803373,  3323697, 26014709,\n",
       "       35153054,  5640383, 28316068, 49381089, 23267869, 38134791,\n",
       "       36622100, 21392435,  7595671, 47448553, 21191890, 15855049,\n",
       "       29760714,  4217265, 46842457, 36622101, 26496274, 11810654,\n",
       "       35455283,   894014,  6663165, 46791145,  6663167, 46057018,\n",
       "       47219191, 31450256, 27735882, 41131056, 45473629, 24821782,\n",
       "        5322344, 48682325, 41026486, 33623596, 26089945, 10221309,\n",
       "       14322709, 27243660, 45435603, 46047691, 46057025, 31411528,\n",
       "       42145038, 14774270, 46338357, 21991699, 41376693, 12958489,\n",
       "        9885952, 25444862, 36622096,   872448, 36575452, 37899982,\n",
       "       29996711, 45095973, 23698841, 45152050, 46057017, 33671998,\n",
       "       18100694, 23784030, 42820844, 35918301, 21798614, 27002093,\n",
       "       45157266, 16767536, 34361474, 47556136, 47866189, 48682320,\n",
       "       29963007, 47456438, 11357394,  7181067, 41849788, 30801274,\n",
       "       47576162,  5309470, 34936540, 19195266, 36835568, 47576165,\n",
       "       47697500,  7237696, 30722900, 46057016, 12174009, 41534377,\n",
       "       44019040,  7055391, 13150664, 38360561, 10075011,   973686,\n",
       "       47914483, 15366051, 12205137, 21769296, 20788043, 43324299,\n",
       "       30445025, 12174024, 25188088, 25360399, 49111371,  2996544,\n",
       "       23349177,  8439294, 16586470, 16586472,  8176122, 21010877,\n",
       "        4923284, 32635244, 17876801, 46047679,   225373, 15515404,\n",
       "       49173925,   758702, 19410422, 36995108, 46842458, 31991819,\n",
       "       18902612,  8815145, 38150192,  5309464, 32182806, 34417851,\n",
       "       46624673,  9835008,  4953396,   397135,  4144178, 41376751,\n",
       "        5309495, 41376750, 11071935, 40425555, 31087900,  2996543,\n",
       "        6445007, 32753078,   132390,  5845424, 23733649, 38134793,\n",
       "       14322685, 41505278, 26222537,  4202835, 45196960, 23863046,\n",
       "       46279955, 38156652, 25753226, 14060841,  7623672,   314956,\n",
       "       21283839, 25868608, 45157269,   184565,  1242992,  4311521,\n",
       "        4727236,  9885955, 12187332, 13805566, 15330980, 18288802,\n",
       "       21873087, 21879885, 22995105, 23267870, 30117958, 33379447,\n",
       "       38083622, 46988815, 48347156, 25739017, 45156965, 10462809,\n",
       "       41505238, 30597339, 44785089, 41376743, 12174037, 36312123,\n",
       "       12409483, 13838601, 31623791, 45435602, 27735881, 12178555,\n",
       "       20641369, 16081675, 45598768, 22374923, 34417832, 40796542,\n",
       "         635835, 39347270, 45157245,   470118,  4689674,  6232170,\n",
       "         131290,   503789, 46025566,  5322345, 40425547,  9007282,\n",
       "       12958478, 25739012, 37570376,  5226259,  9885949, 39984037,\n",
       "       25577783, 41026485, 27690630,  4028602,  4144181, 15571725,\n",
       "       36312122, 40784569, 48347153, 21313926, 39080154, 46338360,\n",
       "       17168589, 48505914,  8379519, 46312683, 19410442, 22109977,\n",
       "       32334197,  5690306, 22177361, 30547585, 34936534, 42928766,\n",
       "        3283954, 36497539,  5226255, 19356842, 28053759, 17262298,\n",
       "       40425546,  4263509, 17653049, 45678566, 45678288, 47488176,\n",
       "       25918936, 10858162,  8812410,  1670496, 23781259,  2605473,\n",
       "         340457, 45204837, 49509389, 42239463, 32692298,  6630822,\n",
       "       35963081, 43929093, 23428459,  2519687,  4937340, 26515104,\n",
       "       48437965,  7243988,  5048762, 25026516, 46028893, 41518746,\n",
       "       34805085, 40103428, 48976276, 18469194, 23781264,   161565,\n",
       "        8439296, 14212394,  2519689, 34762511, 18919372, 48497730,\n",
       "       31991817, 48056001, 23933335, 44526275, 45663307, 32977134,\n",
       "       26014712, 29706402, 46951408,  1143898, 42787717, 44953266,\n",
       "       48713600, 38791482, 18027905, 45129209,  8926484, 47144023,\n",
       "       33632096,  1664053, 47380163, 18949330,   276475, 46338361,\n",
       "       13292989, 42820843,  4659649, 39940421, 48572933, 40146572,\n",
       "       39391818, 24968409, 42247104, 47569183,  5309467,  1670491,\n",
       "       32287274, 14212398,  2568036, 25444860, 46099928,  3084689,\n",
       "       31991822, 27018540, 18409763, 20332626, 23030640, 33509194,\n",
       "         983034, 23933337, 15816612, 14850139, 10583267, 45157274,\n",
       "       42321843, 12673960, 34361475,  5309466,  7819508, 25141858,\n",
       "       43557165, 31991833,  5847847, 47556139, 47877980, 21485707,\n",
       "       46476245, 21603405, 45156942, 17653052, 26668739, 15302116,\n",
       "       31612028,  4659652,  4659648, 18117545, 36575454, 35457021,\n",
       "       32156900, 30997371, 32482610,  5588294, 44582465, 33048579,\n",
       "       39080153,  5322342, 14334497, 36279717,    86790,  5442939,\n",
       "       33481231, 10044800, 23781263, 46280727, 20600405, 26850542,\n",
       "       45636768, 27179007, 49111370,  1699843, 46556306, 41531277,\n",
       "       17477244, 43024623, 13631062, 16470231, 23928573, 24641986,\n",
       "       20641370, 32482612, 32217483,  8974043,  7243986,  4604258,\n",
       "       18278166,   515195, 48709436, 25616578, 12673963, 12274067,\n",
       "       28233249, 38650147, 29628379, 22156991, 18278168, 43368356,\n",
       "       37357005, 48056005, 33429725, 46800650, 48454990, 45100475,\n",
       "       45196036, 38898351, 44081144, 25750308, 23903305,   938466,\n",
       "       35521425,  5302203, 15877352, 26157387, 18930021, 32702064,\n",
       "       28683999, 45147270, 16020464, 10451791, 15366060, 46321465,\n",
       "          54510, 13109431, 15447680,  7856907, 15142337, 20878002,\n",
       "       25854031, 30652086, 31411532, 14901159, 27230083, 34762508,\n",
       "       23733656, 16812586, 15877345, 49314468,  9982648, 28872997,\n",
       "       45129501, 12001871, 42820849, 30562547,  1007735, 18117711,\n",
       "       44869535, 19056624, 44325933, 31900055, 30486155, 45196038,\n",
       "       41485229, 29924076,  2510656, 34828615, 18755924,  3317771,\n",
       "       22109980, 31991813,  6511085, 44638958, 21191891, 30678133,\n",
       "       33318107, 41379555, 16704972,   432634, 25406345, 12958481,\n",
       "       26114031, 12011673, 45655476,  5042214,  5894216, 45157272,\n",
       "       29993539, 33094522, 43024640,  6318750, 30639440, 45100478,\n",
       "       39708154, 45083017, 29484597, 20474101, 48713597,   397111,\n",
       "       23733655, 15513904,  5787747,  8999653, 46575728, 39625949,\n",
       "       45157285, 27735875,  5700459, 31450259, 41474638, 49156930,\n",
       "       37524140, 24798372, 45154326, 15877341, 20877997, 42621538,\n",
       "       49173232, 19180938, 20125935,  5322347,  8779912,  6511082,\n",
       "       47914491, 46833367, 24641992,  1007736,  2510659, 32033413,\n",
       "        7595672, 31382898, 25188113, 36279724, 35899911, 28353230,\n",
       "       16189722, 46817896,  5289071,  3392552,   716400, 41747723,\n",
       "        1597317, 44461848, 29706398, 10759308, 23103412, 29484598,\n",
       "        7802981,  6511078, 25261685, 20510766, 44869589,  6511076,\n",
       "       25026517, 25182774, 32928087,  7766873, 23971508, 10112630,\n",
       "       46047682, 20381126, 25371531, 14486923,  6663168, 41376728,\n",
       "       21843619, 16020536, 18476828, 16084564, 21056435, 38688476,\n",
       "        7277327, 42090120, 41673944,  4913218, 47144022, 35153055,\n",
       "       30636153, 26506198, 23365534, 33928107, 16544887, 46458786,\n",
       "       36622093, 46864556, 33188048, 33431453, 42077056, 27439180,\n",
       "       10221308, 26517953,  3547176, 26515786, 23733650, 21056444,\n",
       "         336316,  3388468, 22188693, 26807780, 10583264,  6912621,\n",
       "       22083061, 39165667, 46367823, 36909426, 22092662, 16979389,\n",
       "         288202, 37140823,  2891152, 21056437, 16704977, 46222137,\n",
       "        8565089, 46325759,  7491105, 48713591, 29462725, 33101129,\n",
       "       46458783, 37021011, 34633329,  2135845, 23780110, 44030599,\n",
       "       40103427, 23349171, 12174042, 35899904,  6511080,   706659,\n",
       "       46280735, 48729237, 16517958, 16244601, 28353236, 12173966,\n",
       "       49396299, 25310782, 15295418,   716407, 47231144, 49374920,\n",
       "       27777712, 42827186,   161566,   288298,   706643, 16812579,\n",
       "       18117786, 18393915, 18402191, 18409736, 18971477, 22277913,\n",
       "       22777761, 23465425, 23496285, 24335864, 24740152, 25495224,\n",
       "       25495236, 26720203,  6232168,  6511054, 16020463, 19195263,\n",
       "       18409738, 20263278, 39133661,  4899992, 25470862, 25495632,\n",
       "       35805054, 39133653, 36745975, 48453869,  2319676, 49381092,\n",
       "        1736154,  7819494, 28653226,    54497, 25914292, 41518722,\n",
       "       41851955, 26850534, 22962928, 12174000, 48529604, 40708084,\n",
       "       24493623, 28692807, 14005173,  7181073, 14774276, 38233951,\n",
       "       46903139, 22108755, 15330979, 22741218, 10687444, 28233243,\n",
       "       13838600,  5132356, 47848507, 49353128, 25750370, 47914484,\n",
       "       18311045,  3248272,  4684042, 44869566, 39048530, 36835554,\n",
       "       31691741,  2510657, 10022308,  2519691, 39635512, 37899989,\n",
       "        4202842, 19424214, 43364451, 19410408, 22149638, 26501929,\n",
       "        1459792, 45157186, 43806189, 34936539, 14334488, 30365644,\n",
       "        9007278,  7277324, 45145955, 34801263, 26642915,    86791,\n",
       "        5309487, 15366059, 12985910, 44745847, 39133651, 34383246,\n",
       "       17915468, 48682312, 22504987,   611236, 26501928, 40905293,\n",
       "       46367837,  4388729,  7460675, 45157273, 46620140, 42496236,\n",
       "       14334492, 45196619,  1699838,  3394364,  5322341, 21208693,\n",
       "       44821989, 30299066, 24467146,  6731422, 21044239,  8922707,\n",
       "       14776979, 13411263, 28319847, 45157271, 32548183,  7863108,\n",
       "       44869554, 12318291, 17389665, 34361473, 44980950, 12985909,\n",
       "       36575451, 34059613, 18902613,  3481136, 22491042, 10525665,\n",
       "       46842449, 29958473,  1748019, 45157185, 11364445, 15295421,\n",
       "         261702, 33924430,  7217534, 18556603, 48098144, 10503873,\n",
       "       46951459, 42864785, 10068872, 49173235, 18408940,  2319683,\n",
       "       21991700, 45157191, 39133647,  4604257,   872453, 45156863,\n",
       "        1030051, 19089165,  2974209, 49111372,  3283929, 35805058,\n",
       "       41505250, 10044795, 29491171, 48943546,  1459793, 23928972,\n",
       "       48437960, 10503871, 15034101, 12071745, 26092749,  1699841,\n",
       "       20284014, 39984035, 18183458, 42090124,  3573252, 16020498,\n",
       "        2319682, 30389986,  8597209, 11652663, 45610823,  1748015,\n",
       "        6511087,  3906706,  4783755,  4038998, 49173234, 46458777,\n",
       "         184561, 49080554, 15176347,  5700463, 10751733, 28306171,\n",
       "       29258272,  7856898, 15059593, 14477823, 36424759, 40708057,\n",
       "       34016123,  3694333, 23102016, 24798871,  2295307, 11281081,\n",
       "       33094531, 18556601, 48682311, 45129494, 45157184, 23475428,\n",
       "       45228465, 45473631, 36312124, 18729166,  2931779,  8710847,\n",
       "       45966121, 42452832, 18560214, 29628382, 27123707, 45207858,\n",
       "       24641993, 37899981,  6924659, 36575456, 48473097, 21798620,\n",
       "       46458784, 34944464, 46618072, 48052817, 43146548,   706644,\n",
       "        8033812,  5974544, 25739013, 21056436, 42969186, 47039148,\n",
       "       26636974, 13298909,   736262, 45157182,    86784, 22030120,\n",
       "       20475868, 47790881, 33094523, 21283838, 28550519, 35899909,\n",
       "       46740781, 28353242, 21760784,  8359243,  3447804, 10653398,\n",
       "       44274903,  3301045, 43024683, 14774277, 22995103, 40103365,\n",
       "       19447548, 42029134, 31118858, 45563158, 49081292, 20841852,\n",
       "       30835240, 46198584, 48020877, 31331186, 47488174, 38156653,\n",
       "        2620652, 31206376, 47219189, 29273075, 33074182, 31505824,\n",
       "        1143923, 26506938, 23348200, 46951464,   515097, 13669538,\n",
       "       31435862, 12207769, 37837827,  6518154, 33379445, 25753243,\n",
       "       44987044, 46951469, 14375330, 14322704,  9198926, 47239280,\n",
       "       29905397, 44869529,  9007267, 30639450])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the current world record for a beer can pyramid?\"\n",
    "D, I = top_k_chunks(query, k=1000)\n",
    "I[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Even fetching the top 1000 matches in index, required chunk isn't found... :(\n",
    "44419780 in I[0], 44419779 in I[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80006427, 0.6291253, 0.6221438, 0.61451036, 0.5936669, 0.58356094, 0.5796839, 0.5711893, 0.56738615, 0.5638323, 0.56263685, 0.5614915, 0.56146127, 0.5585642, 0.5566888, 0.55643344, 0.5559496, 0.55501854, 0.5523143, 0.5492588, 0.5476148, 0.5469228, 0.54552424, 0.54455084, 0.5438782, 0.5436713, 0.5435318, 0.5431305, 0.5429449, 0.54248977, 0.54077667, 0.53899646, 0.53842926, 0.5371756, 0.5366755, 0.53484356, 0.53484356, 0.53484356, 0.5346839, 0.5345394, 0.53318346, 0.53226984, 0.5312338, 0.53103507, 0.53093576, 0.53033006, 0.53018284, 0.53007925, 0.52949023, 0.52894855, 0.5287861, 0.5262939, 0.5258082, 0.5226944, 0.5223705, 0.5221437, 0.5216145, 0.52136683, 0.52118266, 0.5208185, 0.5206651, 0.5203744, 0.5202805, 0.52012444, 0.5199131, 0.5193835, 0.5193835, 0.5193835, 0.5193835, 0.5193835, 0.5193835, 0.51920784, 0.5175997, 0.517492, 0.5167329, 0.51660883, 0.51641655, 0.5157879, 0.51542795, 0.51530284, 0.5147531, 0.51470494, 0.5142274, 0.514047, 0.51338375, 0.5130265, 0.5119648, 0.5118767, 0.5116299, 0.51129663, 0.51103127, 0.51103127, 0.51103127, 0.51103127, 0.51103127, 0.51103127, 0.51103127, 0.51103127, 0.51103127, 0.51103127, 0.51103127, 0.51103127, 0.51103127, 0.51103127, 0.51103127, 0.51103127, 0.51103127, 0.51103127, 0.5109106, 0.5093078, 0.5093007, 0.50895905, 0.5081908, 0.5072104, 0.5066601, 0.5064133, 0.5063057, 0.50618124, 0.50613666, 0.5061022, 0.5054729, 0.5053795, 0.50514567, 0.5045587, 0.5045469, 0.5045412, 0.5043882, 0.5043638, 0.50433016, 0.5041058, 0.5041058, 0.50403625, 0.5038487, 0.50370705, 0.5027695, 0.50204325, 0.5010059, 0.50094634, 0.50052226, 0.5004488, 0.49935263, 0.49911916, 0.49860227, 0.4984995, 0.49821734, 0.49813554, 0.49686503, 0.49679017, 0.49633327, 0.4962756, 0.4962756, 0.4962756, 0.49619442, 0.49551547, 0.49528146, 0.4952669, 0.49480417, 0.49458745, 0.49455714, 0.4935355, 0.49335885, 0.4932804, 0.49324635, 0.49317494, 0.4929279, 0.49267504, 0.4926206, 0.49255568, 0.49255568, 0.49255568, 0.49248093, 0.49216324, 0.49189895, 0.49067146, 0.49030358, 0.4900855, 0.489382, 0.48923543, 0.48919064, 0.4891385, 0.48910388, 0.48905128, 0.4890014, 0.48861936, 0.4884631, 0.4882414, 0.4880735, 0.48782486, 0.48771375, 0.4875601, 0.48738742, 0.48655403, 0.48642403, 0.48617822, 0.48611897, 0.48607987, 0.4854838, 0.48513442, 0.48503187, 0.48483709, 0.4848187, 0.4842167, 0.4838087, 0.48364827, 0.48349512, 0.48325664, 0.4828575, 0.48284522, 0.48283425, 0.48268563, 0.48254412, 0.48201162, 0.4818136, 0.4816458, 0.481574, 0.4813621, 0.48133773, 0.48092157, 0.4805362, 0.48053226, 0.48010117, 0.47864202, 0.4786018, 0.4781471, 0.47782207, 0.47772244, 0.4775796, 0.47756878, 0.4774233, 0.47695112, 0.4769107, 0.47679645, 0.476786, 0.47668704, 0.4766077, 0.47648796, 0.47631985, 0.47630435, 0.47629863, 0.47612923, 0.47611308, 0.47596785, 0.4753841, 0.47509062, 0.47474012, 0.47434935, 0.47412938, 0.47407812, 0.4740653, 0.47399205, 0.47383088, 0.47374183, 0.47370335, 0.4720722, 0.47163767, 0.47141293, 0.47118226, 0.47100705, 0.470151, 0.4698875, 0.46976614, 0.4697559, 0.46972442, 0.46927872, 0.4692778, 0.46915936, 0.46859062, 0.46840817, 0.4678908, 0.46785474, 0.46764272, 0.46758127, 0.46754086, 0.46726954, 0.46726596, 0.46694726, 0.46678922, 0.4667609, 0.4665116, 0.46650636, 0.46649146, 0.46643025, 0.46636575, 0.46631387, 0.46631303, 0.4662825, 0.46605718, 0.46589243, 0.46551603, 0.4651952, 0.46505624, 0.4645304, 0.4645304, 0.4644726, 0.46418628, 0.4639597, 0.46395627, 0.46395627, 0.46395233, 0.46363863, 0.4635045, 0.46348342, 0.46344855, 0.46321905, 0.4631749, 0.463155, 0.46310335, 0.46303633, 0.46290895, 0.46278483, 0.4627819, 0.46258876, 0.4624748, 0.4623798, 0.46237302, 0.46232185, 0.46204078, 0.46191412, 0.4617859, 0.4612264, 0.46106648, 0.46099663, 0.4607755, 0.46074075, 0.46056047, 0.46052438, 0.46024257, 0.4599756, 0.45993382, 0.45979828, 0.45978904, 0.45974445, 0.4597295, 0.45960122, 0.45953116, 0.45948052, 0.45946312, 0.4592564, 0.45925087, 0.4592374, 0.4592319, 0.45921364, 0.45919818, 0.4590381, 0.45898646, 0.45898584, 0.45887116, 0.45876515, 0.4586395, 0.45860404, 0.45852524, 0.45822716, 0.45810258, 0.45767456, 0.45762762, 0.45752773, 0.45747852, 0.45744574, 0.4574168, 0.45698223, 0.45690334, 0.4568935, 0.4565031, 0.4563985, 0.4561231, 0.45608443, 0.4560573, 0.45585766, 0.45530993, 0.45529762, 0.4550654, 0.45487583, 0.45466942, 0.4546683, 0.45466042, 0.45446151, 0.45430082, 0.454184, 0.45356888, 0.4535501, 0.45344055, 0.4531847, 0.45310366, 0.45300293, 0.45239687, 0.45196503, 0.45182532, 0.45181102, 0.45177972, 0.4517592, 0.4517592, 0.4517293, 0.45169896, 0.4516354, 0.45157748, 0.4512328, 0.4512328, 0.4512328, 0.4512328, 0.4511511, 0.45106322, 0.45104957, 0.45102328, 0.4509672, 0.45091438, 0.4506004, 0.4502462, 0.4502045, 0.44998723, 0.44983554, 0.44932145, 0.4492499, 0.4492131, 0.44918498, 0.4491433, 0.44913304, 0.44893652, 0.4488463, 0.44883585, 0.4486723, 0.4485728, 0.4484681, 0.4478659, 0.44786358, 0.4478527, 0.4478252, 0.44773415, 0.4477334, 0.44760388, 0.44758254, 0.44756028, 0.44715467, 0.4471019, 0.447032, 0.44681907, 0.4460572, 0.44548088, 0.44513375, 0.4447714, 0.44473085, 0.4445638, 0.4443796, 0.44434565, 0.4443239, 0.44409692, 0.44394684, 0.4438317, 0.44361198, 0.44360918, 0.4434453, 0.44337577, 0.4431849, 0.44302338, 0.44257838, 0.44256866, 0.44255704, 0.44255108, 0.442541, 0.44215417, 0.4421221, 0.44211984, 0.44192415, 0.4419183, 0.44171754, 0.44171733, 0.4415653, 0.44139475, 0.44133902, 0.44112647, 0.440611, 0.44050163, 0.44041213, 0.44014406, 0.43998218, 0.4399464, 0.43990564, 0.4398023, 0.43979895, 0.43954507, 0.4394766, 0.43925732, 0.43914628, 0.4389137, 0.4389137, 0.43860906, 0.43856704, 0.43836817, 0.437986, 0.4378188, 0.4375937, 0.4375698, 0.43723682, 0.43723258, 0.4371841, 0.43683174, 0.4367156, 0.43668652, 0.4365889, 0.43652558, 0.43621254, 0.43600792, 0.43581116, 0.4358027, 0.43573806, 0.43551004, 0.43544886, 0.43544748, 0.4353675, 0.43530124, 0.43523645, 0.43496042, 0.43467796, 0.4342259, 0.43397185, 0.43394902, 0.43343836, 0.4333747, 0.4331147, 0.43285072, 0.4328179, 0.4326898, 0.43252745, 0.43236232, 0.43227732, 0.4321902, 0.43213308, 0.43207306, 0.43199986, 0.43184245, 0.43183106, 0.43181455, 0.4315975, 0.43152177, 0.4315193, 0.43131122, 0.43128663, 0.43127328, 0.4312144, 0.4311905, 0.4311507, 0.43089467, 0.43068203, 0.43056792, 0.4304137, 0.43040645, 0.4300265, 0.42964405, 0.42954293, 0.42929995, 0.42862904, 0.42839992, 0.4283728, 0.42836064, 0.42803642, 0.42787713, 0.42785776, 0.4275766, 0.42730382, 0.42729905, 0.42707708, 0.4269591, 0.42692798, 0.42691657, 0.4268713, 0.4268464, 0.4268382, 0.42683548, 0.42678672, 0.42676723, 0.4263106, 0.42617762, 0.42617673, 0.42610836, 0.4259082, 0.4255033, 0.42508137, 0.42498204, 0.42493862, 0.42457795, 0.42456502, 0.4243912, 0.42437187, 0.4243516, 0.42423737, 0.4241712, 0.42407894, 0.42354786, 0.42352468, 0.423509, 0.42348516, 0.42348054, 0.42311472, 0.4226735, 0.42264467, 0.4225808, 0.42247897, 0.42233062, 0.4223237, 0.42213628, 0.4220724, 0.42188066, 0.42177796, 0.42167836, 0.42158067, 0.42109016, 0.42091694, 0.42088354, 0.4208523, 0.42072695, 0.42072695, 0.4205854, 0.42033926, 0.4201897, 0.42005366, 0.4200282, 0.41992456, 0.41947162, 0.41912863, 0.41910613, 0.41898298, 0.41892368, 0.41879678, 0.4187199, 0.41867056, 0.41846228, 0.4180204, 0.41783154, 0.41750348, 0.4174136, 0.41701126, 0.41698825, 0.41682902, 0.41669664, 0.41647872, 0.41639555, 0.41636366, 0.41626006, 0.41619337, 0.41593084, 0.41585615, 0.41578466, 0.41572925, 0.41550452, 0.4154019, 0.4153635, 0.4152295, 0.41501206, 0.41479528, 0.41473776, 0.41472554, 0.4147098, 0.41465884, 0.41449282, 0.41433227, 0.41427708, 0.41427404, 0.41393036, 0.4137506, 0.41359472, 0.4135254, 0.41342187, 0.4134212, 0.41331133, 0.41330674, 0.41329136, 0.41311115, 0.4129293, 0.41287413, 0.41245696, 0.41245696, 0.41245696, 0.41245696, 0.41245696, 0.41245696, 0.41245696, 0.41245696, 0.41245696, 0.41245696, 0.41245696, 0.41245696, 0.41245696, 0.41245696, 0.41245696, 0.41245696, 0.41245696, 0.41245696, 0.41239232, 0.41227117, 0.41225415, 0.41210532, 0.4118498, 0.41124418, 0.41119674, 0.4108527, 0.4107066, 0.41050866, 0.41002172, 0.40995723, 0.40991533, 0.40987504, 0.40973967, 0.40972027, 0.409632, 0.4094735, 0.40945923, 0.40939015, 0.40897205, 0.40874523, 0.40862125, 0.40854916, 0.4084984, 0.40834844, 0.40818435, 0.4081578, 0.40808755, 0.40773958, 0.4076984, 0.40763026, 0.4075284, 0.4074639, 0.4071018, 0.4068185, 0.40637708, 0.40611485, 0.40584254, 0.40536994, 0.40534234, 0.40515074, 0.40500998, 0.404647, 0.4045261, 0.4045027, 0.40439117, 0.40430415, 0.40421408, 0.4041866, 0.40412664, 0.40408674, 0.40390712, 0.40384376, 0.40373138, 0.40368515, 0.40366846, 0.40359157, 0.4034036, 0.4032743, 0.40318483, 0.40316683, 0.40253592, 0.40225536, 0.40166506, 0.40163887, 0.40163767, 0.4008577, 0.400814, 0.4007129, 0.40063596, 0.40037587, 0.40019298, 0.40016592, 0.40013397, 0.39978802, 0.39973375, 0.39970022, 0.3996198, 0.39956933, 0.39953035, 0.3991627, 0.3989766, 0.398937, 0.39873862, 0.3983465, 0.3974325, 0.39736113, 0.3967577, 0.39671153, 0.39634317, 0.3962496, 0.39590937, 0.39585656, 0.3957536, 0.3957129, 0.39509493, 0.39503467, 0.3944421, 0.39433286, 0.39429617, 0.394261, 0.39412197, 0.39410233, 0.39406106, 0.3938014, 0.39355898, 0.39257342, 0.39220262, 0.39203912, 0.39176434, 0.39122248, 0.3905829, 0.39041263, 0.39022797, 0.39007163, 0.39001432, 0.38981986, 0.38977334, 0.38971612, 0.38964993, 0.38953513, 0.38896477, 0.3889507, 0.38893875, 0.3887777, 0.38845775, 0.38800204, 0.38798034, 0.38758197, 0.38743135, 0.3874132, 0.3873839, 0.38677114, 0.38676763, 0.38671625, 0.3864599, 0.3863177, 0.38631573, 0.3863091, 0.3862782, 0.3860821, 0.3860277, 0.38590854, 0.38556552, 0.38548535, 0.38528335, 0.38452116, 0.38438237, 0.38424242, 0.3841987, 0.38400936, 0.38355318, 0.38342172, 0.38340068, 0.38322288, 0.3832078, 0.3830364, 0.3823904, 0.38197362, 0.38181826, 0.38172615, 0.38172323, 0.38135517, 0.38082537, 0.3807341, 0.3806547, 0.38033748, 0.3801096, 0.37980086, 0.3797385, 0.3796217, 0.37951896, 0.37902406, 0.37877458, 0.37870705, 0.37859786, 0.37811393, 0.37805897, 0.37760845, 0.3773015, 0.3771639, 0.3771324, 0.37704304, 0.3770333, 0.37702766, 0.3769898, 0.37668133, 0.37660742, 0.3765083, 0.37608737, 0.37566006, 0.37541294, 0.37535948, 0.37478918, 0.37474152, 0.37445694, 0.3740648, 0.373488, 0.37272507, 0.3725157, 0.37250704, 0.3724867, 0.37233165, 0.3721854, 0.37191945, 0.37140706, 0.3713916, 0.37125516, 0.37118512, 0.3710161, 0.3705374, 0.37032053, 0.3697083, 0.36935562, 0.36876553, 0.36875254, 0.36871442, 0.36841607, 0.36805862, 0.36722732, 0.3661819, 0.36612636, 0.3660394, 0.36586612, 0.3656519, 0.3649158, 0.364511, 0.36414668, 0.3640719, 0.36403567, 0.36401236, 0.3632539, 0.36323202, 0.36308557, 0.36261293, 0.36248046, 0.36198694, 0.36151877, 0.36102876, 0.36059716, 0.36050007, 0.35991412, 0.35980332, 0.35931402, 0.35884076, 0.35832638, 0.3579873, 0.35798663, 0.35680354, 0.3561353, 0.3553177, 0.35519052, 0.3549483, 0.353993, 0.35373533, 0.35360095, 0.3532155, 0.3524573, 0.35228723, 0.35176855, 0.35104862, 0.35002762, 0.34952682, 0.3493107, 0.34921652, 0.34864798, 0.34573776, 0.3455971, 0.34482226, 0.34450448, 0.3442154, 0.34277534, 0.34277183, 0.342574, 0.34220612, 0.34213313, 0.34180805, 0.34104088, 0.34055126, 0.33918437, 0.3384815, 0.33794054, 0.3378755, 0.33745226, 0.33742803, 0.33634168, 0.33614078, 0.33556044, 0.3346169, 0.33305192, 0.33287457, 0.33286113, 0.331277, 0.32891515, 0.3276372, 0.32680225, 0.32644618, 0.32480356, 0.32480356, 0.32167652, 0.32157275, 0.32065862, 0.3192374, 0.318132, 0.31713718, 0.31503093, 0.31296676, 0.31085956, 0.31062162, 0.30789515, 0.29965484, 0.29216588, 0.25280672]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the current world record for a beer can pyramid?\"\n",
    "D, I = top_k_chunks(query, k=1000)\n",
    "\n",
    "scores = []\n",
    "emb_query = query_encoder.encode([query])\n",
    "for idx in I[0]:\n",
    "    emb= query_encoder.encode([chunks[idx]])\n",
    "    score = np.dot(emb_query.flatten(), emb.flatten())\n",
    "    scores.append(score)\n",
    "\n",
    "print(list(reversed(list(sorted(scores)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
